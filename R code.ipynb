{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["R Code"],"metadata":{"id":"H9bTIygyexQk"}},{"cell_type":"code","source":["#merge data\n","install.packages(\"readxl\")\n","install.packages(\"dplyr\")\n","install.packages(\"purrr\")\n","install.packages(\"writexl\")\n","\n","library(readxl)\n","library(dplyr)\n","library(purrr)\n","library(writexl)\n","\n","file_path <- \"data_file_path\"\n","excel_files <- list.files(path = file_path, pattern = \"*.xlsx\", full.names = TRUE)\n","\n","data_list <- excel_files %>%\n","  map(~ read_excel(.))\n","\n","merged_data <- reduce(data_list, ~ right_join(.x, .y, by = c(\"state\", \"category\", \"item_code\", \"item_name\", \"package_type\")))\n","# merged_data <- reduce(data_list, ~ inner_join(.x, .y, by = \"store_number\"))\n","\n","View(merged_data)\n","write_xlsx(merged_data, path = \"data_file_path\\\\merged_tequila_data.xlsx\")\n","\n","map(data_list, colnames)"],"metadata":{"id":"EgVlPdK_ezsI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#cleaning data\n","#data cleaning\n","# Loading\n","install.packages(\"writexl\")\n","library(tidyverse)\n","library(lubridate)\n","library(randomForest)\n","library(caret)\n","library(tm)\n","library(text2vec)\n","library(SnowballC)\n","library(glmnet)\n","library(vip)\n","library(stringr)\n","library(dplyr)\n","library(ROCR)\n","library(ggplot2)\n","library(writexl)\n","#library(fastDummies)\n","library(gbm)\n","library(readxl)\n","# xlsx files\n","clean_data <- read_excel(\"merged_tequila_data.xlsx\")\n","summary(clean_data)\n","#change to numeric\n","clean_data$TequilaUnder65 <- as.numeric(clean_data$TequilaUnder65)\n","clean_data$TequilaOver65 <- as.numeric(clean_data$TequilaOver65)\n","# Extract zipcode\n","clean_data <- clean_data %>%\n","  mutate(zipcode= str_extract(Store_Address, \"\\\\d{5}$\")) %>%\n","  mutate(zipcode= as.numeric(zipcode))%>%\n","  mutate(zipcode= as.factor(zipcode))\n","#standardize open_date\n","clean_data$Open_Date <- as.Date(clean_data$Open_Date, format = \"%Y-%m-%d\")\n","summary(clean_data$Open_Date)\n","\n","\n","# Define a mapping of tequila brand names to their categories\n","category_mapping <- c(\n","  \"Blanco/Silver\" = \"Silver|Blanco\",\n","  \"Reposado\" = \"Reposado\",\n","  \"Anejo\" = \"Anejo\",\n","  \"Extra Anejo\" = \"Extra Anejo\",\n","  \"Mezcal\" = \"Mezcal\",\n","  \"Cristalino\" = \"Cristalino\",\n","  \"Gold\"= \"Gold\")\n","# Create a new column for tequila category\n","clean_data <- clean_data %>%\n","  mutate(tequila_category = case_when(\n","    str_detect(item_name, category_mapping[\"Blanco/Silver\"]) ~ \"Blanco/Silver\",\n","    str_detect(item_name, category_mapping[\"Reposado\"]) ~ \"Reposado\",\n","    str_detect(item_name, category_mapping[\"Anejo\"]) ~ \"Anejo\",\n","    str_detect(item_name, category_mapping[\"Extra Anejo\"]) ~ \"Extra Anejo\",\n","    str_detect(item_name, category_mapping[\"Mezcal\"]) ~ \"Mezcal\",\n","    str_detect(item_name, category_mapping[\"Cristalino\"]) ~ \"Cristalino\",\n","    str_detect(item_name, category_mapping[\"Gold\"]) ~ \"Gold\",\n","    TRUE ~ \"Other\" )) # Default category for unmatched brands  ))\n","additional_mapping <- c(\n","  \"Jose Cuervo Especial Silv Tequila\" = \"Blanco/Silver\",\n","  \"Don Julio 1942 Tequila\"= \"Anejo\",\n","  \"Patron Tequila Gran Platinum\" = \"Blanco/Silver\",\n","  \"Hornitos Plata Tequila\"= \"Blanco/Silver\",\n","  \"Altos PlataTequila\"= \"Blanco/Silver\",\n","  \"Maestro Dobel Diamante\"= \"Reposado\",\n","  \"Herradura Ultra Tequila\"= \"Anejo\",\n","  \"Lobos 1707 Joven Tequila\"= \"Blanco/Silver\",\n","  \"400 Conejos Joven Oaxaca\"= \"Mezcal\",\n","  \"Gran Centenario Plata Tequila\" = \"Blanco/Silver\",\n","  \"Avion Reserva 44\"= \"Anejo\",\n","  \"Don Julio Alma Miel Joven Tequila\"= \"Cristalino\",\n","  \"Tequila Ocho Plata\" = \"Blanco/Silver\",\n","  \"Sauza Tres Generaciones Plata\"=\"Blanco/Silver\",\n","  \"Corralejo 99000 Horas Tequila\" = \"Anejo\",\n","  \"Jose Cuervo Rsrva DeFamiliaPlatino\" = \"Blanco/Silver\",\n","  \"Montezuma White\"= \"Blanco/Silver\",\n","  \"Clase Azul Plata Tequila\"= \"Blanco/Silver\",\n","  \"Tarantula  Azul Tequila\"= \"Blanco/Silver\",\n","  \"Casa Dragones Tequila Joven\"= \"Blanco/Silver\",\n","  \"Don Fulano Fuerte Tequila\"= \"Blanco/Silver\",\n","  \"Gran Centenario Leyenda Extra Anej\"= \"Anejo\",\n","  \"Don Fulano Fuerte Tequila \"= \"Anejo\",\n","  \"Asombroso Platino Tequila\"= \"Blanco/Silver\",\n","  \"Herradura Seleccion SupremaTequila\"= \"Blanco/Silver\",\n","  \"San Matias Gran Reserva Tequila\"= \"Anejo\",\n","  \"Sauza Conmemorativo\"= \"Gold\",\n","  \"Durango White DSS\"= \"Blanco/Silver\",\n","  \"Republic Plata Texas Bottle\"= \"Blanco/Silver\",\n","  \"Del Majuey San Luis del Rio\"= \"Mezcal\",\n","  \"Don Julio Rosado\"= \"Reposado\")\n","\n","#Update the tequila_category in clean_data using additional_mapping\n","clean_data <- clean_data %>%\n","  mutate(tequila_category = case_when(\n","    item_name %in% names(additional_mapping) ~ additional_mapping[item_name],  # Assign from additional mapping\n","    TRUE ~ tequila_category  # Keep existing category if not in additional mapping\n","  ))\n","other_brands <- clean_data %>%\n","  filter(Sales_Bucket == \"Sales excluded for model test\") %>%\n","  select (item_name,tequila_category)%>%\n","  distinct() %>%\n","  filter(tequila_category== \"Other\")\n","other_brands_counts <- clean_data %>%\n","  filter(tequila_category == \"Other\") %>%\n","  group_by(item_name) %>%\n","  summarise(count = n()) %>%\n","  arrange(desc(count))\n","\n","#change to factor-all catergorical columns\n","clean_data <- clean_data %>%\n","  mutate(state = as.factor(state)) %>%\n","  mutate(package_type = as.factor(package_type))%>%\n","  mutate(item_name = as.factor(item_name))%>%\n","  mutate(Sales_Bucket = as.factor(Sales_Bucket))%>%\n","  mutate(PriceZone = as.factor(PriceZone))%>%\n","  mutate(item_code=as.factor(item_code))%>%\n","  mutate(store_number=as.factor(store_number))%>%\n","  mutate(Store_Size=as.factor(Store_Size))%>%\n","  mutate(tequila_category=as.factor(tequila_category))\n","\n","# Function to calculate total ml for entries with \"ml\" and bottle count\n","calculate_total_ml <- function(package_type) {\n","  # Initialize total_ml as NA\n","  total_ml <- NA\n","  # Check if the entry matches the \"quantity-bottle count gft\" format (e.g., \"375-3gft\" or \"50ml-4p\")\n","  if (grepl(\"^[0-9]+ml?-[0-9]+[a-z]*$\", package_type, ignore.case = TRUE)) {\n","    # Extract the ml quantity before \"-\"\n","    ml_quantity <- as.numeric(sub(\"ml?-.*\", \"\", package_type))\n","    # Extract the number of units after \"-\"\n","    unit_count <- as.numeric(sub(\".*-([0-9]+)[a-z]*$\", \"\\\\1\", package_type))\n","    # Calculate total ml\n","    total_ml <- ml_quantity * unit_count\n","  } else if (grepl(\"^[0-9]+-[0-9]+gft$\", package_type)) {\n","    # Extract the ml quantity before \"-\"\n","    ml_quantity <- as.numeric(sub(\"-.*\", \"\", package_type))\n","    # Extract the bottle count after \"-\"\n","    bottle_count <- as.numeric(sub(\".*-([0-9]+)gft\", \"\\\\1\", package_type))\n","    # Calculate total ml\n","    total_ml <- ml_quantity * bottle_count\n","  } else if (grepl(\"^[0-9]+(\\\\.[0-9]+)?ml\", package_type, ignore.case = TRUE)) {\n","    # Handle entries with \"ml\" followed by other text, like \"mlBox\"\n","    total_ml <- as.numeric(gsub(\"ml.*\", \"\", package_type, ignore.case = TRUE))\n","  } else if (grepl(\"^[0-9]+(\\\\.[0-9]+)?L$\", package_type, ignore.case = TRUE)) {\n","    # Handle entries with liters, convert to ml, allowing for decimal values\n","    total_ml <- as.numeric(gsub(\"L\", \"\", package_type, ignore.case = TRUE)) * 1000\n","  } else if (grepl(\"^[0-9]+gft$\", package_type, ignore.case = TRUE)) {\n","    # Handle entries like \"375gft\" as ml quantity\n","    total_ml <- as.numeric(gsub(\"gft\", \"\", package_type, ignore.case = TRUE))\n","  } else {\n","    total_ml <- NA\n","  }\n","\n","  return(total_ml)\n","}\n","\n","# Apply the function to each row in the \"package_type\" column\n","clean_data$package_type_ml <- sapply(clean_data$package_type, calculate_total_ml)\n","\n","#find price per 100ml\n","# Calculate price per 100 ml\n","calculate_price_per_100_ml <- function(package_type_ml, Retail) {\n","  if (package_type_ml > 0) {\n","    return((Retail / package_type_ml) * 100)\n","  } else {\n","    return(NA)  # Handle cases where ml is zero or missing\n","  }\n","}\n","\n","#fill nas in retail\n","temp_data <- clean_data %>% filter(is.na(Retail))\n","clean_data$Retail[is.na(clean_data$Retail)] <- 18.99\n","\n","# Apply this function to create a new column\n","clean_data$price_per_100_ml <- mapply(calculate_price_per_100_ml, clean_data$package_type_ml, clean_data$Retail)\n","\n","# First, calculate sales_adjusted for each group based on item_code, and fill missing sales_dollars_L52wk values\n","clean_data <- clean_data %>%\n","  group_by(item_code) %>%\n","  mutate(\n","    normalized_households = Households / max(Households, na.rm = TRUE),  # Normalize within item_code group\n","    sales_adjusted = mean(sales_dollars_L52wk, na.rm = TRUE) * normalized_households\n","  ) %>%\n","  ungroup() %>%\n","  mutate(\n","    sales_dollars_L52wk = ifelse(is.na(sales_dollars_L52wk), sales_adjusted, sales_dollars_L52wk)\n","  )\n","# Next, calculate sales_adjusted by state and Retail, then fill missing sales values\n","clean_data <- clean_data %>%\n","  group_by(state, Retail) %>%\n","  mutate(\n","    normalized_households = Households / max(Households, na.rm = TRUE),  # Normalize within state and Retail group\n","    sales_adjusted2 = mean(sales_dollars_L52wk, na.rm = TRUE) * normalized_households\n","  ) %>%\n","  ungroup() %>%\n","  mutate(\n","    sales_dollars_L52wk = ifelse(is.na(sales_dollars_L52wk), sales_adjusted2, sales_dollars_L52wk)\n","  )\n","# Calculate sales_adjusted for Retail, and fill missing sales values\n","clean_data <- clean_data %>%\n","  group_by(Retail) %>%\n","  mutate(\n","    normalized_households = Households / max(Households, na.rm = TRUE),\n","    sales_adjusted3 = mean(sales_dollars_L52wk, na.rm = TRUE) * normalized_households\n","  ) %>%\n","  ungroup() %>%\n","  mutate(\n","    sales_dollars_L52wk = ifelse(is.na(sales_dollars_L52wk), sales_adjusted3, sales_dollars_L52wk)\n","  )\n","# Create Price Bands\n","clean_data <- clean_data %>%\n","  mutate(price_band = ifelse(Retail < 20, 1,\n","                             ifelse(Retail < 65, 2,\n","                                    ifelse(Retail < 150, 3, 4))),\n","         price_band = as.factor(price_band))\n","# Remaining NAs will be filled with the state, priceband\n","clean_data <- clean_data %>%\n","  group_by(state,price_band) %>%\n","  mutate(normalized_households = Households / max(Households, na.rm = TRUE),\n","         sales_adjusted4 = mean(sales_dollars_L52wk, na.rm = TRUE) * normalized_households\n","  ) %>%\n","  ungroup() %>%\n","  mutate(\n","    sales_dollars_L52wk = ifelse(is.na(sales_dollars_L52wk), sales_adjusted4, sales_dollars_L52wk)\n","  )\n","summary(clean_data$sales_dollars_L52wk)\n","#Calculate avg_pod. Use the overall median if all NAs for item code. Only when non-missing values exist, then normalize Households and calculate pod_adjusted.\n","overall_median_pod <- median(clean_data$points_of_distribution_L52wk, na.rm = TRUE)\n","\n","clean_data <- clean_data %>%\n","  group_by(item_code) %>%\n","  mutate(\n","    avg_pod = ifelse(all(is.na(points_of_distribution_L52wk)), overall_median_pod, mean(points_of_distribution_L52wk, na.rm = TRUE)),,\n","    normalized_households = Households / max(Households),\n","    pod_adjusted = avg_pod * normalized_households\n","  ) %>%\n","  ungroup()\n","clean_data <- clean_data %>%\n","  mutate(\n","    points_of_distribution_L52wk = ifelse(is.na(points_of_distribution_L52wk), pod_adjusted, points_of_distribution_L52wk)\n","  )\n","summary(clean_data$points_of_distribution_L52wk)\n","\n","\n","#Filling NAs in L52w_in_Stock with 0 which doesn't have stock for that store\n","clean_data <- clean_data %>%\n","  mutate(\n","    L52W_in_Stock = ifelse(\n","      is.na(L52W_in_Stock) &\n","        ((item_code == \"130634750\" & store_number == \"1008\") |\n","           (item_code == \"130634750\" & store_number == \"1010\")),\n","      0,\n","      L52W_in_Stock\n","    )\n","  )\n","\n","#Filling NAs in L52W_in_Stock with 52 which have stock in that store\n","clean_data <- clean_data %>%\n","  mutate(\n","    L52W_in_Stock = ifelse(\n","      is.na(L52W_in_Stock) &\n","        ((item_code == \"130634750\" & store_number == \"1001\") |\n","           (item_code == \"149223375\" & store_number == \"1121\")),\n","      52,\n","      L52W_in_Stock\n","    )\n","  )\n","\n","#find the volatality score\n","clean_data <- clean_data %>%\n","  group_by(item_code) %>%\n","  mutate(\n","    mean_sales = mean(),\n","    sd_sales = ifelse(is.na(sd(sales_dollars_L52wk)),0,sd(sales_dollars_L52wk)),\n","    volatility_score = sd_sales / mean_sales\n","  )\n","# Apply K-means clustering to households data with 4 clusters\n","clean_data$households_cluster <- kmeans(clean_data$Households, centers = 4)$cluster\n","# Convert clusters to factors for coloring\n","clean_data$households_cluster <- as.factor(clean_data$households_cluster)\n","# Calculate mean households for each cluster and assign labels\n","cluster_means <- clean_data %>%\n","  group_by(households_cluster) %>%\n","  summarize(mean_households = mean(Households)) %>%\n","  arrange(mean_households) %>%\n","  mutate(density_label = c(\"Low\", \"Medium\", \"High\", \"Very High\")) # Rename to density_label\n","# View the summary table\n","print(cluster_means)\n","# Join back to the original data with new labels\n","clean_data <- clean_data %>%\n","  left_join(cluster_means %>% select(households_cluster, density_label), by = \"households_cluster\") %>%\n","  mutate(households_density = factor(density_label, levels = c(\"Low\", \"Medium\", \"High\", \"Very High\")))\n","\n","#create a celebrity_owned column to check if the brand is owned by celebrity\n","celebrity_brands <- c(\"Casamigos\", \"818\", \"Teremana\", \"DeLeón\", \"Sauza\", \"Cabo Wabo\", \"Patron\",\n","                      \"Partida\", \"Ocho\", \"Herradura\", \"512\", \"El Tesoro\", \"Codigo 1530\", \"Dulce Vida\",\n","                      \"Avión\", \"Kosmos\", \"El Bandido Yankee\", \"Santo\", \"Lobos 1707\", \"Dos Primos\", \"Vida\",\n","                      \"Insolito\", \"Casa Del Sol\", \"Pantalones Organic\", \"Honor\", \"Gran Coramino\",\n","                      \"Dos Hombres\", \"Próspero\", \"Villa One\", \"JAJA\", \"Santo Fino\", \"Cincoro\", \"Flecha Azul\")\n","\n","# Function to check if an item is celebrity-owned\n","celebrity_owned <- function(item_name, brands) {\n","  any(sapply(brands, function(brand) grepl(brand, item_name, ignore.case = TRUE)))\n","}\n","\n","# Apply the function to create a new column\n","clean_data$celebrity_owned <- as.integer(sapply(clean_data$item_name, celebrity_owned, brands = celebrity_brands))\n","\n","#categorizing households\n","# Calculate the min and max values from the Households column\n","#min_households <- min(clean_data$Households, na.rm = TRUE)\n","#max_households <- max(clean_data$Households, na.rm = TRUE)\n","\n","# Calculate the interval\n","#interval <- (max_households - min_households) / 4\n","\n","#clean_data <- clean_data %>%\n","#  mutate(\n","#   household_density = case_when(\n","#      Households >= min_households & Households < (min_households + interval) ~ \"low density\",\n","#      Households >= (min_households + interval) & Households < (min_households + 2 * interval) ~ \"med density\",\n","#      Households >= (min_households + 2 * interval) & Households < (min_households + 3 * interval) ~ \"high density\",\n","#      Households >= (min_households + 3 * interval) ~ \"very high density\")\n","#  )\n","\n","# Categorize Medium_HH_Income\n","clean_data <- clean_data %>%\n","  mutate( Income_Category = case_when(\n","    Median_HH_Income < 75000 ~ \"Lower\",\n","    Median_HH_Income >= 75000 & Median_HH_Income < 100000 ~ \"Middle\",\n","    Median_HH_Income >= 100000 & Median_HH_Income < 150000 ~ \"Upper-Middle\",\n","    Median_HH_Income >= 150000 ~ \"High\" ),\n","    Income_Category = factor(Income_Category, levels = c(\"Lower\", \"Middle\", \"Upper-Middle\", \"High\")) )\n","\n","# Create Sales Per Store Column\n","clean_data <- clean_data %>%\n","  mutate(sales_per_store = ifelse(points_of_distribution_L52wk == 0, 0 ,sales_dollars_L52wk/points_of_distribution_L52wk))\n","# Change date to years since opening\n","clean_data <- clean_data %>%\n","  mutate(\n","    years_open = as.numeric(difftime(Sys.Date(), Open_Date, units = \"days\")) / 365.25\n","  )\n","\n","anejo_tequila_search <- read_csv(\"anejo_tequila_search.csv\")\n","clean_data <- clean_data %>%\n","  left_join(anejo_tequila_search, by = \"state\")\n","\n","google_trends <- read_csv(\"google_trends.csv\")\n","clean_data <- clean_data %>%\n","  left_join(google_trends, by = \"state\")\n","\n","reposado_tequila_search <- read_csv(\"reposado_tequila_search.csv\")\n","clean_data <- clean_data %>%\n","  left_join(reposado_tequila_search, by = \"state\")\n","\n","silver_tequila_search <- read_csv(\"silver_tequila_search.csv\")\n","clean_data <- clean_data %>%\n","  left_join(silver_tequila_search, by = \"state\")\n","\n","cheap_tequila_search <- read_csv(\"cheap_tequila_search.csv\")\n","clean_data <- clean_data %>%\n","  left_join(cheap_tequila_search, by = \"state\")\n","\n","best_tequila_search <- read_csv(\"best_tequila_search.csv\")\n","clean_data <- clean_data %>%\n","  left_join(best_tequila_search, by = \"state\")\n","\n","clean_data <- clean_data %>%\n","  mutate(state = as.factor(state))\n","\n","#DOWNLOAD EXCEL FOR EDA\n","#write_xlsx(clean_data, \"clean_data.xlsx\")\n","# This will save the file in your working directory. To check the path:\n","#getwd()\n","\n","\n","#removing helper columns and non-model columns\n","clean_data <- clean_data %>%\n","  select(-category,-vintage,-State,-Store_Name,-Store_Address,-sales_adjusted,-package_type_ml,-pod_adjusted,\n","         -avg_pod,-mean_sales,-sd_sales,-households_cluster,-density_label,-Households, -sales_adjusted2,\n","         -sales_adjusted3,-sales_adjusted4, -zipcode, -Open_Date,-item_name)\n","summary(clean_data)\n","\n","# Validation\n","sapply(clean_data, class)\n","# All are numeric, factor, or date\n","\n","#split the data into train and test\n","train<- clean_data %>% filter(Sales_Bucket == \"Sales included\")\n","test<- clean_data %>% filter(Sales_Bucket == \"Sales excluded for model test\")\n","\n","anyNA(train)\n","na_rows <- train[!complete.cases(train), ]"],"metadata":{"id":"nnj7kLlJBlG0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#EDA Code\n","# Plot box plot to see households categories\n","ggplot(clean_data, aes(x = households_density, y = Households, fill = households_density)) +\n","  geom_boxplot(alpha = 0.7) +\n","  labs(title = \"Households Distribution by Density Level\", x = \"Density Level\", y = \"Number of Households\") +\n","  scale_fill_manual(values = c(\"Low\" = \"#1b9e77\", \"Medium\" = \"#d95f02\", \"High\" = \"#7570b3\", \"Very High\" = \"#e7298a\")) +\n","  theme_minimal()\n","\n","#bar grapgh to see mean sales by state by tequila category\n","ggplot(sales_summary, aes(x = state, y = mean_normalized_sales, fill = tequila_category)) +\n","  geom_bar(stat = \"identity\", position = \"dodge\") +\n","  labs(title = \"Mean Normalized Sales by Tequila Category and State\",\n","       x = \"State\",\n","       y = \"Mean Normalized Sales (L52W)\") +\n","  theme(axis.text.x = element_text(angle = 45, hjust = 1))"],"metadata":{"id":"7fx-Vphd40WY","colab":{"base_uri":"https://localhost:8080/","height":108},"executionInfo":{"status":"error","timestamp":1730917572881,"user_tz":300,"elapsed":154,"user":{"displayName":"Srishti Gupta","userId":"01618190119084851550"}},"outputId":"92faa7df-fb98-4e16-f0bb-a47324db76b4"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-1-251e9158557f>, line 3)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-251e9158557f>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    ggplot(clean_data, aes(x = households_density, y = Households, fill = households_density)) +\u001b[0m\n\u001b[0m                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","source":["# Initial Modeling"],"metadata":{"id":"j0EWvBa6knxD"}},{"cell_type":"code","source":["#split the data into full dataset and final test for submission.\n","full<- clean_data %>% filter(Sales_Bucket == \"Sales included\")\n","final_test<- clean_data %>% filter(Sales_Bucket == \"Sales excluded for model test\")\n","\n","# Split into basic train and test\n","set.seed(1)\n","train_indices <- sample(seq_len(nrow(full)), size = 0.8 * nrow(full))\n","\n","# Split the data\n","train <- full[train_indices, ]\n","test <- full[-train_indices, ]\n","\n","###############################################################################\n","\n","##########\n","### Baseline Model RMSE\n","\n","baseline_prediction <- rep(mean(labels_test, na.rm = TRUE), length(labels_test))\n","baseline_rmse <- RMSE(baseline_prediction, labels_test)\n","baseline_MAE <- MAE(baseline_prediction, labels_test)\n","print(baseline_rmse)\n","print(baseline_MAE)\n","\n","##########\n","### Random Forest does not work as is. Too many item codes.\n","\n","# model <- randomForest(Normalized_Sales_L52W ~ ., data = full, ntree = 500)\n","\n","\n","##########\n","### Boosting does not work because we need to convert to integer/numeric for each.\n","### Doing so loses a lot of information\n","\n","#dtrain <- xgb.DMatrix(data = as.matrix(full[, -which(names(full) == \"Normalized_Sales_L52W\")]),\n","#                     label = full$Normalized_Sales_L52W)\n","#model <- xgb.train(params = list(objective = \"reg:squarederror\"), data = dtrain, nrounds = 100)\n","\n","##########\n","### Catboost does not work because there is not a catboost regression module in R.\n","### Might consider doing in python.\n","\n","# Run these to download catboost. If/When prompted, update all by entering 1 into the console.\n","#install.packages('remotes')\n","#remotes::install_url('https://github.com/catboost/catboost/releases/download/v1.2.7/catboost-R-windows-x86_64-1.2.7.tgz', INSTALL_opts = c(\"--no-multiarch\", \"--no-test-load\"))\n","\n","# Quickstart guide: https://catboost.ai/en/docs/concepts/r-quickstart\n","\n","library(catboost)\n","\n","# Separate into features and labels\n","features <- train %>% select(-Normalized_Sales_L52W)\n","labels <- train$Normalized_Sales_L52W\n","\n","features_test <- test %>% select(-Normalized_Sales_L52W)\n","labels_test <- test$Normalized_Sales_L52W\n","\n","train_pool <- catboost.load_pool(data = features, label = labels)\n","\n","model <- catboost.train(train_pool,  NULL,\n","                        params = list(loss_function = 'RMSE',\n","                                      iterations = 100, metric_period=10))\n","model_MAE <- catboost.train(train_pool, NULL,\n","                        params = list(loss_function = 'MAE',\n","                                      iterations = 100, metric_period = 10))\n","\n","\n","\n","test_pool <- catboost.load_pool(features_test)\n","\n","prediction <- catboost.predict(model, test_pool)\n","prediction_MAE <- catboost.predict(model_MAE, test_pool)\n","\n","catboost_rmse <- RMSE(prediction,labels_test)\n","catboost_MAE <- MAE(prediction_MAE, labels_test)\n","\n","print(baseline_rmse)\n","print(catboost_rmse)\n","\n","print(baseline_MAE)\n","print(catboost_MAE)\n","\n","baseline_error <- .5*baseline_rmse + .5*baseline_MAE\n","catboost_error <- .5*catboost_rmse + .5*catboost_MAE\n","\n","print(paste(\"Baseline Error: \",  baseline_error))\n","print(paste(\"Catboost Error: \",  catboost_error))\n","\n","#> print(baseline_MAE)\n","#[1] 4186.446\n","#> print(baseline_rmse)\n","#[1] 10024.44\n","\n","#> print(baseline_MAE)\n","#[1] 4186.446\n","#> print(catboost_MAE)\n","#[1] 2174.655\n","\n","# [1] \"Baseline Error:  7105.44308138542\"\n","# [1] \"Catboost Error:  3310.07157977977\"\n"],"metadata":{"id":"06RSk9WbkfBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###############################################################################\n","## Cross Validation and Grid Search\n","\n","# Split into basic train and test\n","set.seed(1)\n","train_indices <- sample(seq_len(nrow(full)), size = 0.9 * nrow(full))\n","\n","# Split the data\n","train <- full[train_indices, ]\n","holdout <- full[-train_indices, ]\n","\n","# Separate into train/validation and holdout set.Uncomment if not doing gridsearch.\n","\n","#features <- train %>% select(-Normalized_Sales_L52W)\n","#labels <- train$Normalized_Sales_L52W\n","\n","#features_holdout <- holdout %>% select(-Normalized_Sales_L52W)\n","#labels_holdout <- holdout$Normalized_Sales_L52W\n","\n","\n","\n","grid_search <- function(){\n","\n","  learning_rate = c(0.01, 0.03, 0.1)\n","  depth = c(4, 6, 8)\n","  l2_leaf_reg = c(1, 3)\n","  iterations = c(500)\n","\n","  # Change the second number to be equal to numfolds.\n","  foldnumber <- seq(1,5,1)\n","\n","  numfolds <- 2\n","\n","  train_shuffled <- train[sample(nrow(train)),]\n","  train_x <- train_shuffled %>% select(-Normalized_Sales_L52W)\n","  train_y <- train_shuffled$Normalized_Sales_L52W\n","\n","\n","  #separate data into k equally-sized folds\n","  #cut() will assign \"fold numbers\" to each instance\n","  folds <- cut(seq(1,nrow(train_shuffled)),breaks=numfolds,labels=FALSE)\n","\n","  # Initialize an empty dataframe to store results\n","  results <- data.frame(fold = numeric(),\n","                        learning_rate = numeric(),\n","                        depth = numeric(),\n","                        l2_leaf_reg = numeric(),\n","                        RMSE = numeric(),\n","                        MAE = numeric(),\n","                        Error = numeric(),\n","                        stringsAsFactors = FALSE)\n","\n","\n","  #nested loops to tune these three parameters\n","  print('fold, learning_rate, depth, l2_leaf_reg, iterations, RMSE, MAE, Error')\n","  for(f in c(1:length(unique(folds)))){\n","    for(i in c(1:length(learning_rate))){\n","      for(j in c(1:length(depth))){\n","        for(k in c(1:length(l2_leaf_reg))){\n","          for (l in c(1:length(iterations))){\n","\n","            set.seed(sample(1:100000,1,replace=TRUE))\n","\n","            thisfold <- foldnumber[f]\n","            thislearning_rate <- learning_rate[i]\n","            thisdepth <- depth[j]\n","            thisl2_leaf_reg <- l2_leaf_reg[k]\n","            thisiteration <- iterations[l]\n","\n","            valid_inds <- which(folds==f,arr.ind=TRUE)\n","            valid_fold <- train_x[valid_inds, ]\n","            valid_fold_y <- train_y[valid_inds]\n","            train_fold <- train_x[-valid_inds, ]\n","            train_fold_y <- train_y[-valid_inds]\n","\n","            train_data <- catboost.load_pool(data = train_fold,\n","                                             label = train_fold_y)\n","            valid_data <- catboost.load_pool(data = valid_fold,\n","                                             label = valid_fold_y)\n","\n","            model_RMSE <- catboost.train(\n","              learn_pool = train_data,\n","              test_pool = valid_data,\n","              params = list(\n","                loss_function = \"RMSE\",  # Adjust for regression tasks\n","                learning_rate = thislearning_rate,\n","                depth = thisdepth,\n","                l2_leaf_reg = thisl2_leaf_reg,\n","                iterations = thisiteration,\n","                eval_metric = \"RMSE\",\n","                use_best_model = TRUE\n","              )\n","            )\n","\n","            model_MAE <- catboost.train(\n","              learn_pool = train_data,\n","              test_pool = valid_data,\n","              params = list(\n","                loss_function = \"MAE\",  # Adjust for regression tasks\n","                learning_rate = thislearning_rate,\n","                depth = thisdepth,\n","                l2_leaf_reg = thisl2_leaf_reg,\n","                iterations = thisiteration,\n","                eval_metric = \"MAE\",\n","                use_best_model = TRUE\n","              )\n","            )\n","\n","            prediction_RMSE <- catboost.predict(model_RMSE, valid_data)\n","            prediction_MAE <- catboost.predict(model_MAE, valid_data)\n","\n","            catboost_rmse <- RMSE(prediction_RMSE,valid_fold_y)\n","            catboost_MAE <- MAE(prediction_MAE, valid_fold_y)\n","\n","            catboost_error <- .5*catboost_rmse + .5*catboost_MAE\n","\n","\n","            #print the performance for every combination\n","            print(paste(thisfold, thislearning_rate, thisdepth, thisl2_leaf_reg, thisiteration, catboost_rmse, catboost_MAE, catboost_error,sep = \", \"))\n","            # Append the results to the dataframe\n","            results <- rbind(results, data.frame(fold = thisfold,\n","                                                 learning_rate = thislearning_rate,\n","                                                 depth = thisdepth,\n","                                                 l2_leaf_reg = thisl2_leaf_reg,\n","                                                 iterations = thisiteration,\n","                                                 RMSE = catboost_rmse,\n","                                                 MAE = catboost_MAE,\n","                                                 Error = catboost_error))\n","\n","          }\n","        }\n","      }\n","    }\n","  }\n","  return(results)\n","}\n","\n","result <- grid_search()\n"],"metadata":{"id":"g0uqa6lsEaUv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###############################################################################\n","###### Determining Best Model Parameters from the Grid Search\n","\n","fold_results <- result %>% group_by(learning_rate, depth, l2_leaf_reg, iterations) %>% summarise(\n","  mean_RMSE = mean(RMSE),\n","  mean_MAE = mean(MAE),\n","  mean_error = mean(Error))\n","\n","best_error <- min(fold_results$mean_error)\n","\n","best_params <- fold_results %>% filter(mean_error == best_error)\n","\n","################################################################################\n","###### Training Best Model on Final Validation Set\n","\n","train_data <- catboost.load_pool(data = features,\n","                                 label = labels)\n","valid_data <- catboost.load_pool(data = features_test,\n","                                 label = labels_test)\n","\n","model_RMSE <- catboost.train(\n","  learn_pool = train_data,\n","  test_pool = valid_data,\n","  params = list(\n","    loss_function = \"RMSE\",  # Adjust for regression tasks\n","    learning_rate = best_params$learning_rate,\n","    depth = best_params$depth,\n","    l2_leaf_reg = best_params$l2_leaf_reg,\n","    iterations = best_params$iterations,\n","    eval_metric = \"RMSE\",\n","    use_best_model = TRUE\n","  )\n",")\n","\n","model_MAE <- catboost.train(\n","  learn_pool = train_data,\n","  test_pool = valid_data,\n","  params = list(\n","    loss_function = \"RMSE\",  # Adjust for regression tasks\n","    learning_rate = best_params$learning_rate,\n","    depth = best_params$depth,\n","    l2_leaf_reg = best_params$l2_leaf_reg,\n","    iterations = best_params$iterations,\n","    eval_metric = \"MAE\",\n","    use_best_model = TRUE\n","  )\n",")\n","\n","\n","### Making Predictions\n","prediction_RMSE <- catboost.predict(model_RMSE, valid_data)\n","prediction_MAE <- catboost.predict(model_MAE, valid_data)\n","\n","### Final Prediction\n","prediction_final <- .5*(prediction_RMSE + prediction_MAE)\n","\n","### Merging Final Predictions with Validation Data\n","prediction_final <- as.vector(prediction_final)\n","test_with_predictions <- cbind(test, prediction_final = prediction_final)\n","\n","### Merging Train and Validation Data\n","train$prediction_final <- NA\n","full_df <- rbind(train,test_with_predictions)\n","\n","\n","### Calculating Residuals\n","full_df <- full_df %>% mutate(residuals = prediction_final - Normalized_Sales_L52W )\n","\n","### Calculating Final Error\n","final_RMSE <- RMSE(test_with_predictions$prediction_final,test_with_predictions$Normalized_Sales_L52W)\n","final_MAE <- MAE(test_with_predictions$prediction_final,test_with_predictions$Normalized_Sales_L52W)\n","final_error <- .5*final_RMSE + .5*final_MAE\n","\n","### Final Error is 2613.9\n","\n","\n","### Writing to xlsx\n","write_xlsx(full_df, \"full_df.xlsx\")"],"metadata":{"id":"2Ip6os54-MU4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###feature engineering for over and under performing grouped by store\n","\n","\n","full_residuals_data <- read_excel(\"clean_data.xlsx\")\n","summary(full_residuals_data)\n","full_residuals_data <- full_residuals_data %>%\n","  group_by(store_number) %>%\n","  mutate(\n","    mean_residual = mean(residuals),   # Mean residual for the store\n","    sd_residual = sd(residuals),       # Standard deviation of residuals for the store\n","    lower_threshold = mean_residual - 2* sd_residual,  # Lower threshold (Mean - 2 * SD)\n","    upper_threshold = mean_residual + 2* sd_residual   # Upper threshold (Mean + 2 * SD)\n","  ) %>%\n","  ungroup()  # Remove grouping after calculation\n","\n","# Flag underperforming or overperforming stores based on thresholds\n","full_residuals_data <- full_residuals_data %>%\n","  mutate(\n","    underperforming = ifelse(residuals < lower_threshold, 1, 0),\n","    overperforming = ifelse(residuals > upper_threshold, 1, 0)\n","  )\n","write_xlsx(full_residuals_data, \"full_residuals_data.xlsx\")"],"metadata":{"id":"VRwvr8i6totu"},"execution_count":null,"outputs":[]}]}